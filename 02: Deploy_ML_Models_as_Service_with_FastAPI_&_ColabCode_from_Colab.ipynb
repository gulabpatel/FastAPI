{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02: Deploy ML Models as Service with FastAPI & ColabCode from Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gulabpatel/FastAPI/blob/main/02%3A%20Deploy_ML_Models_as_Service_with_FastAPI_%26_ColabCode_from_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PX3mXJ_Uu5b"
      },
      "source": [
        "Video walkthrough the code : https://www.youtube.com/watch?v=7-igAakUUTY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfkUNsC_T2qy"
      },
      "source": [
        "!pip install colabcode\n",
        "!pip install fastapi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjR3OXrZUWbN"
      },
      "source": [
        "from colabcode import ColabCode\n",
        "from fastapi import FastAPI"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00z03aC9YVGk"
      },
      "source": [
        "cc = ColabCode(port=12000, code=False)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFXBGHaNUk3h"
      },
      "source": [
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def read_root():\n",
        "  return {\"message\": \"Welcome to the Future!\"}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzWXXJs-UmFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e556e66-358b-40e1-b2d4-77cc5e053b6d"
      },
      "source": [
        "cc.run_app(app=app)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Public URL: NgrokTunnel: \"https://fd4d00e7a46a.ngrok.io\" -> \"http://localhost:12000\"\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [166]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:12000 (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     2409:4063:6e13:69ad:e026:1ab5:ba8f:c7ec:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     2409:4063:6e13:69ad:e026:1ab5:ba8f:c7ec:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [166]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQI5-R6TVKa_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE3gaKk7UpEV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a8aade-6379-4354-d871-4403bd949b0d"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "\n",
        "iris = load_iris()\n",
        "model = GaussianNB()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.1)\n",
        "model_f = model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model score: \", model.score(X_train, y_train))\n",
        "print(\"Test Accuracy: \", model.score(X_test, y_test))\n",
        "\n",
        "pickle.dump(model_f, open(\"model_gb.pkl\", \"wb\"))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model score:  0.9629629629629629\n",
            "Test Accuracy:  0.8666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sWUbNKGW9ZX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cebeb87e-0a8f-4a98-d513-6ce4a9e24ab2"
      },
      "source": [
        "%%writefile models.py\n",
        "from pydantic import BaseModel, conlist\n",
        "from typing import List\n",
        "\n",
        "\n",
        "class Iris(BaseModel):\n",
        "    data: List[conlist(float, min_items=4, max_items=4)]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing models.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMpFW8OAV2r3"
      },
      "source": [
        "import pickle\n",
        "import logging\n",
        "from fastapi import FastAPI\n",
        "from models import Iris\n",
        "\n",
        "app = FastAPI(title=\"ML Models as API on Google Colab\", description=\"with FastAPI and ColabCode\", version=\"1.0\")\n",
        "\n",
        "# # Initialize logging\n",
        "# my_logger = logging.getLogger()\n",
        "# my_logger.setLevel(logging.DEBUG)\n",
        "# logging.basicConfig(level=logging.DEBUG, filename='logs.log')\n",
        "\n",
        "model = None\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "def load_model():\n",
        "    global model\n",
        "    model = pickle.load(open(\"model_gb.pkl\", \"rb\"))\n",
        "\n",
        "@app.post(\"/api\", tags=[\"prediction\"])\n",
        "async def get_predictions(iris: Iris):\n",
        "    try:\n",
        "        data = dict(iris)['data']\n",
        "        print(data)\n",
        "        iris_types = {\n",
        "            0: 'setosa',\n",
        "            1: 'versicolor',\n",
        "            2: 'virginica'\n",
        "        }\n",
        "        prediction = list(map(lambda x: iris_types[x], model.predict(data).tolist()))\n",
        "        log_proba = model.predict_log_proba(data).tolist()\n",
        "        return {\"prediction\": prediction, \"log_proba\": log_proba}\n",
        "    except:\n",
        "        my_logger.error(\"Something went wrong!\")\n",
        "        return {\"prediction\": \"error\"}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFl9Ga5uW5ED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a437ee0b-2a14-4060-b22e-3a4be17eb81f"
      },
      "source": [
        "cc.run_app(app=app)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Public URL: NgrokTunnel: \"https://ba9d1e0799d4.ngrok.io\" -> \"http://localhost:12000\"\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [166]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:12000 (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     2409:4063:6e13:69ad:e026:1ab5:ba8f:c7ec:0 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "INFO:     2409:4063:6e13:69ad:e026:1ab5:ba8f:c7ec:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     2409:4063:6e13:69ad:e026:1ab5:ba8f:c7ec:0 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "INFO:     2409:4063:6e13:69ad:e026:1ab5:ba8f:c7ec:0 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "INFO:     2409:4063:6e13:69ad:e026:1ab5:ba8f:c7ec:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     2409:4063:6e13:69ad:e026:1ab5:ba8f:c7ec:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
            "[[4.5, 3.5, 2.5, 1.5]]\n",
            "INFO:     2409:4063:6e13:69ad:e026:1ab5:ba8f:c7ec:0 - \"POST /api HTTP/1.1\" 200 OK\n",
            "[[3.0, 2.0, 1.0, 3.5]]\n",
            "INFO:     2409:4063:6e13:69ad:e026:1ab5:ba8f:c7ec:0 - \"POST /api HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETLzZIEub1ut"
      },
      "source": [
        "##### To run on browser click on : https://ba9d1e0799d4.ngrok.io/docs"
      ]
    }
  ]
}